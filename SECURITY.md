# Security Policy — CI-AI

The CI-AI project prioritizes the safety, privacy, and well-being of humanity in all contributions. 
This document describes how to responsibly report vulnerabilities or safety concerns.

---

##  Supported Versions

| Version   | Supported |
|-----------|------------|
| main      | ✅ Active  |
| others    | ❌ Not supported |

Only the **main branch** is actively supported. Other branches or forks may not receive security updates.

---

##  Reporting a Vulnerability or Unsafe Behavior

If you discover a vulnerability, unsafe behavior, or systemic risk in CI-AI: 

1. **Do not disclose publicly** until it has been reviewed. 
2. Create a **private security advisory** through the GitHub Security tab. 
3. Or contact the maintainers directly at: **garbgmannjohan@gmail.com**. 

---

##  What to Report

- Code vulnerabilities (e.g., unsafe dependencies, exploits). 
- Unsafe AI outputs that could cause systemic harm (e.g., prescriptive medical advice, disinformation, weapons guidance). 
- Privacy leaks (e.g., exposure of sensitive data). 
- Manipulative or harmful behaviors that bypass current termination rules. 

---

##  Our Commitments

- All reports will be acknowledged within **7 days**. 
- We will provide an update on the status within **30 days**. 
- Valid reports will be addressed before disclosure, whenever possible. 

---

##  Humanity-First Reminder

CI-AI is an **open research prototype**. It should not be deployed as-is in production environments. 
All contributors share the responsibility of ensuring that the project remains aligned with humanity’s long-term survival and flourishing.

